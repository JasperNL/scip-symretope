from checkutil.evalutil import Instance, read_outfile
import pathlib
import pandas as pd
import numpy as np
import re
import itertools

datas = []

# For each file of final_miplib_symretope:
instancenamepatt = re.compile(r"flowersnark(\d+)_3")
for outfile in itertools.chain(
    pathlib.Path("results_flowersnark/").glob("*final_flowersnark*.out"),
    pathlib.Path("results_isopr_nosubtree/").glob("*final_flowersnark*.out")
):
    print(outfile)

    instance: Instance
    for instance in read_outfile(outfile):
        n = int(instancenamepatt.match(instance.instancename).group(1))

        datas.append([n, instance.instancename, instance.settings, instance.totaltime,
            instance.solved == "problem is solved", instance.status])

df = pd.DataFrame(datas, columns=["n", "name", "sett", "time", "solved", "status"])


# Get all possible settings and names
setts = df["sett"].unique()
names = df["name"].unique()

num_settings_per_instance = df.groupby(["name", "sett"])["time"].count().max()
print(f"{num_settings_per_instance} runs per setting.")

print("# All settings")
print(setts)

# list incomplete instances (missing for a setting)
print()
print("# Testing instances whether they are all solved")
failed_instances = set()
for name, gdf in df.groupby("name"):
    failed = False 

    # Failing checks
    if gdf["time"].isna().any():
        print(f"Instance {name} has no solving time")
        failed = True
    if gdf["sett"].unique().shape != setts.shape:
        failed = True
        print(f"Instance {name} misses settings")
    if gdf.groupby("sett")["time"].count().min() < num_settings_per_instance:
        failed = True
        print(f"Instance {name} has less runs per setting than {num_settings_per_instance}")

    if failed:
        failed_instances.add(name)
        # print(gdf)
        print()

# restrict df to the non-failed instances.
df = df[df.apply(lambda s: s["name"] not in failed_instances, axis=1)].copy()

# Prepare for geometric means
df["logtimeplus10"] = np.log(df["time"] + 10)

with open("results_revision_flowersnark.csv", "w") as f:
    df.to_csv(f)
df_complete = df

topmatter = r"""% generated by gentable_miplib.py
\begin{tabular}{l*{7}{rr}}
\toprule
& \multicolumn{2}{c}{\tt nosym}&
\multicolumn{2}{c}{\tt gen}&
\multicolumn{2}{c}{\tt group}&
\multicolumn{2}{c}{\tt weak}&
\multicolumn{2}{c}{\tt strong}&
\multicolumn{2}{c}{\tt isopr mib}&
\multicolumn{2}{c}{\tt isopr}
\\
\cmidrule(l{1pt}r{1pt}){2-3}
\cmidrule(l{1pt}r{1pt}){4-5}
\cmidrule(l{1pt}r{1pt}){6-7}
\cmidrule(l{1pt}r{1pt}){8-9}
\cmidrule(l{1pt}r{1pt}){10-11}
\cmidrule(l{1pt}r{1pt}){12-13}
\cmidrule(l{1pt}r{1pt}){14-15}
relabeling
& time(s) & S
& time(s) & S
& time(s) & S
& time(s) & S
& time(s) & S
& time(s) & S
& time(s) & S
\\
\midrule
"""
midmatter = r"""\cmidrule{2-15}"""
botmatter = r"""\bottomrule
\end{tabular}
"""

def gen_table_flowersnark(df):
    for sett, gdf in df.groupby("sett"):
        nsolved = gdf["solved"].sum()
        ntotal = gdf["solved"].count()
        geomtime = np.exp(gdf["logtimeplus10"].mean()) - 10
        print(f"{sett:60s} {geomtime:10.2f} {nsolved:4d}/{ntotal:4d} ({nsolved/ntotal*100: 5.1f}%)")

    print()

    df["sett_short"] = df["sett"].apply(lambda s: s.split("_")[2])
    for sett, gdf in df.groupby("sett_short"):
        nsolved = gdf["solved"].sum()
        ntotal = gdf["solved"].count()
        geomtime = np.exp(gdf["logtimeplus10"].mean()) - 10
        print(f"{sett:60s} {geomtime:10.2f} {nsolved:4d}/{ntotal:4d} ({nsolved/ntotal*100: 5.1f}%)")

    print()

    # Generating LaTeX table
    print(topmatter)

    # for flowersnark
    def detect_relabeling_heuristic(sett):
        if sett in ["settings_isopr_minimalindexbranching", "settings_isopr_minimalindexbranching_avoidsubtreenodes",
            "settings_isopr_ostrowskidynamicbranching", "settings_isopr_ostrowskidynamicbranching_avoidsubtreenodes"]:
            return "original"
        spl = sett.split("_")
        if spl[-1] in ["nosym", "norelabel"]:
            return "original"
        if spl[-1] not in ["min", "respect"]:
            return "max"
        else:
            return spl[-1]

    # # for miplib
    # def detect_relabeling_heuristic(sett):
    #     spl = sett.split("_")
    #     if len(spl) < 4 or spl[3] == "norelabel":
    #         return "original"
    #     assert spl[3] == "relabel"
    #     if len(spl) == 5:
    #         return "max"
    #     return spl[4]

    df["relabeling_heuristic"] = df["sett"].apply(detect_relabeling_heuristic)

    df_dict = {key: gdf.copy() for key, gdf in df.groupby(["sett_short", "relabeling_heuristic"])}
    heurs = ["original", "max", "min", "respect"]
    setts = ["nosym", "nosymretope", "moresymresack", "nopeek", "peek",
             "minimalindexbranching", "ostrowskidynamicbranching"]

    # Row per heuristic
    for heur in heurs:
        # One column for the settings.
        s = f"{heur:20s}"
        for sett in setts:
            # Set of columns of matrix
            gdf = df_dict.get((sett, heur))
            if gdf is None:
                s += "&    -- &   --"
            else:
                nsolved = gdf["solved"].sum()
                ntotal = gdf["solved"].count()
                geomtime = np.exp(gdf["logtimeplus10"].mean()) - 10
                s += f"& {geomtime:10.2f} & {nsolved:4d}"
        s += r"\\"
        print(s)

    print(midmatter)

    # One column for the settings.
    df_dict = {key: gdf.copy() for key, gdf in df.groupby("sett_short")}
    s = f"{'aggregated':20s}"
    for sett in setts:
        # Set of columns of matrix
        gdf = df_dict.get(sett)
        if gdf is None:
            #    "&     419.78 &   65"
            s += "&    --      &   --"
        else:
            nsolved = gdf["solved"].sum()
            ntotal = gdf["solved"].count()
            geomtime = np.exp(gdf["logtimeplus10"].mean()) - 10
            s += f"& {geomtime:10.2f} & {nsolved/ntotal*100:2.0f}\%"
    s += r"\\"
    print(s)

    # Compared to group
    # One column for the settings.
    df_dict = {key: gdf.copy() for key, gdf in df.groupby("sett_short")}
    gdf_group = df_dict.get("moresymresack")
    if gdf_group is not None:
        s = f"{'cmp. to group':20s}"
        for sett in setts:
            # Set of columns of matrix
            gdf = df_dict.get(sett)
            if gdf is None:
                #    "&     419.78 &   65"
                s += "&    --      &   --"
            elif sett == "moresymresack":
                s += "&    --      &   --"
            else:
                nsolved = (gdf["solved"].sum() / gdf["solved"].count()) /\
                    (gdf_group["solved"].sum() / gdf_group["solved"].count()) * 100 - 100
                geomtime = (np.exp(gdf["logtimeplus10"].mean()) - 10) / (np.exp(gdf_group["logtimeplus10"].mean()) - 10) * 100 - 100
                s += f"& {geomtime:+10.0f}\% & {nsolved:+2.0f}\%"
        s += r"\\"
        print(s)

    print(botmatter)

# Generate table for all instances.
print("# All instances")
df = df_complete
gen_table_flowersnark(df)

# Restricted to instances that cannot be solved by nosym.
df = df_complete
max_n_nosym_solved = df[(df["sett"] == "settings_final_nosym") & (df["solved"])]["n"].max()
print(f"# Restricted to instances for n > {max_n_nosym_solved}")
df = df[df["n"] > max_n_nosym_solved].copy()
gen_table_flowersnark(df)

print("# Restricted to instances that need at least 10s to solve")
df = df_complete
sel = df.groupby("name")["time"].min() > 10
print(f"  {sel.sum()} instances.")
gen_table_flowersnark(df.set_index("name")[sel].reset_index())

print("# Restricted to instances that need at least 100s to solve")
df = df_complete
sel = df.groupby("name")["time"].min() > 100
print(f"  {sel.sum()} instances.")
gen_table_flowersnark(df.set_index("name")[sel].reset_index())

breakpoint()

# # Possibly: Restrict to instances that are solved within 10 seconds
# fast_instances = set(df[df["time"] < 100.0]["name"].unique())
# df = df[df.apply(lambda s: s["name"] not in fast_instances, axis=1)].copy()

# # Possibly: Restrict to instances that are actually solved
# solved_instances = set(df[df["solved"]]["name"].unique())
# df = df[df.apply(lambda s: s["name"] in solved_instances, axis=1)].copy()



print()